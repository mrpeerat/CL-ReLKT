{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-14T09:32:56.564473Z",
     "iopub.status.idle": "2022-06-14T09:32:56.564869Z",
     "shell.execute_reply": "2022-06-14T09:32:56.564718Z",
     "shell.execute_reply.started": "2022-06-14T09:32:56.564700Z"
    },
    "tags": []
   },
   "source": [
    "## Sentence-level online prompty mining: MLQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:21:59.013823Z",
     "iopub.status.busy": "2022-06-14T10:21:59.013543Z",
     "iopub.status.idle": "2022-06-14T10:22:04.990727Z",
     "shell.execute_reply": "2022-06-14T10:22:04.990273Z",
     "shell.execute_reply.started": "2022-06-14T10:21:59.013762Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import re\n",
    "import os, sys\n",
    "import json\n",
    "import glob\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "\n",
    "from exploring_sentence_level import (\n",
    "    load_model,\n",
    "    mine_prompt_gt,  \n",
    "    segment_sentence,\n",
    "    run_online_prompt_mining\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Download dataset\n",
    "\n",
    "```bash\n",
    "cd ../scripts\n",
    "bash ./download_mlqa.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:22:04.992342Z",
     "iopub.status.busy": "2022-06-14T10:22:04.992149Z",
     "iopub.status.idle": "2022-06-14T10:22:05.677192Z",
     "shell.execute_reply": "2022-06-14T10:22:05.676507Z",
     "shell.execute_reply.started": "2022-06-14T10:22:04.992324Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLQA_BASE_DIR = '../data/mlqa/MLQA_V1/'\n",
    "\n",
    "mlqa_xx = {}\n",
    "MLQA_LANGS = ['en', 'ar', 'de', 'es', 'hi', 'vi', 'zh']\n",
    "for lang in MLQA_LANGS:\n",
    "    mlqa_xx[f'{lang}_val'] = json.load(open(os.path.join(MLQA_BASE_DIR, 'dev', f'dev-context-en-question-{lang}.json'), 'r'))['data'],\n",
    "    mlqa_xx[f'{lang}_test'] = json.load(open(os.path.join(MLQA_BASE_DIR, 'test', f'test-context-en-question-{lang}.json'), 'r'))['data'],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:22:05.678417Z",
     "iopub.status.busy": "2022-06-14T10:22:05.678031Z",
     "iopub.status.idle": "2022-06-14T10:22:05.690162Z",
     "shell.execute_reply": "2022-06-14T10:22:05.689430Z",
     "shell.execute_reply.started": "2022-06-14T10:22:05.678364Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2389"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlqa_xx['ar_test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:22:05.691413Z",
     "iopub.status.busy": "2022-06-14T10:22:05.691163Z",
     "iopub.status.idle": "2022-06-14T10:22:05.695418Z",
     "shell.execute_reply": "2022-06-14T10:22:05.694844Z",
     "shell.execute_reply.started": "2022-06-14T10:22:05.691388Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_squad_answer_str(context, qas):\n",
    "    context_qa_pairs = []\n",
    "    for qa in qas:\n",
    "        question = qa['question']\n",
    "        answer = qa['answers'][0]['text']\n",
    "        answer_start = qa['answers'][0]['answer_start']\n",
    "        context_qa_pairs.append((context, question, answer, answer_start))\n",
    "    return context_qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:22:05.698133Z",
     "iopub.status.busy": "2022-06-14T10:22:05.697843Z",
     "iopub.status.idle": "2022-06-14T10:22:30.697724Z",
     "shell.execute_reply": "2022-06-14T10:22:30.697182Z",
     "shell.execute_reply.started": "2022-06-14T10:22:05.698100Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlqa_xx_dataset = defaultdict(lambda: {'val':[], 'test': []})\n",
    "for lang in MLQA_LANGS:\n",
    "\n",
    "    for split_name in ['val', 'test']:\n",
    "        for i, item in enumerate(mlqa_xx[f'{lang}_{split_name}'][0]):\n",
    "\n",
    "            paragraphs = item['paragraphs']\n",
    "\n",
    "            for j, paragraph in enumerate(paragraphs):\n",
    "\n",
    "                context = paragraph['context']\n",
    "                context_qa_pairs = get_squad_answer_str(context=context, qas=paragraph['qas'])\n",
    "\n",
    "                for context_qa_pair in context_qa_pairs:\n",
    "                    context, question, answer, answer_start = context_qa_pair\n",
    "                    gt_sentence = mine_prompt_gt(context_qa_pair)\n",
    "                    qa_item = {\n",
    "                         'question': question,\n",
    "                            'context': context,\n",
    "                            'segmented_context': segment_sentence(context),\n",
    "                            'answer': answer,\n",
    "                            'answer_start': answer_start,\n",
    "                            'gt_sentence': gt_sentence,\n",
    "                    }\n",
    "                    mlqa_xx_dataset[lang][split_name].append(qa_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:22:30.698832Z",
     "iopub.status.busy": "2022-06-14T10:22:30.698482Z",
     "iopub.status.idle": "2022-06-14T10:22:30.702788Z",
     "shell.execute_reply": "2022-06-14T10:22:30.701798Z",
     "shell.execute_reply.started": "2022-06-14T10:22:30.698811Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 5335)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlqa_xx_dataset['ar']['val']), \\\n",
    "len(mlqa_xx_dataset['ar']['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:22:30.704271Z",
     "iopub.status.busy": "2022-06-14T10:22:30.703847Z",
     "iopub.status.idle": "2022-06-14T10:22:30.709506Z",
     "shell.execute_reply": "2022-06-14T10:22:30.708852Z",
     "shell.execute_reply.started": "2022-06-14T10:22:30.704247Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Who analyzed the biopsies?',\n",
       " 'context': 'In 1994, five unnamed civilian contractors and the widows of contractors Walter Kasza and Robert Frost sued the USAF and the United States Environmental Protection Agency. Their suit, in which they were represented by George Washington University law professor Jonathan Turley, alleged they had been present when large quantities of unknown chemicals had been burned in open pits and trenches at Groom. Biopsies taken from the complainants were analyzed by Rutgers University biochemists, who found high levels of dioxin, dibenzofuran, and trichloroethylene in their body fat. The complainants alleged they had sustained skin, liver, and respiratory injuries due to their work at Groom, and that this had contributed to the deaths of Frost and Kasza. The suit sought compensation for the injuries they had sustained, claiming the USAF had illegally handled toxic materials, and that the EPA had failed in its duty to enforce the Resource Conservation and Recovery Act (which governs handling of dangerous materials). They also sought detailed information about the chemicals to which they were allegedly exposed, hoping this would facilitate the medical treatment of survivors. Congressman Lee H. Hamilton, former chairman of the House Intelligence Committee, told 60 Minutes reporter Lesley Stahl, \"The Air Force is classifying all information about Area 51 in order to protect themselves from a lawsuit.\"',\n",
       " 'segmented_context': ['In 1994, five unnamed civilian contractors and the widows of contractors Walter Kasza and Robert Frost sued the USAF and the United States Environmental Protection Agency.',\n",
       "  'Their suit, in which they were represented by George Washington University law professor Jonathan Turley, alleged they had been present when large quantities of unknown chemicals had been burned in open pits and trenches at Groom.',\n",
       "  'Biopsies taken from the complainants were analyzed by Rutgers University biochemists, who found high levels of dioxin, dibenzofuran, and trichloroethylene in their body fat.',\n",
       "  'The complainants alleged they had sustained skin, liver, and respiratory injuries due to their work at Groom, and that this had contributed to the deaths of Frost and Kasza.',\n",
       "  'The suit sought compensation for the injuries they had sustained, claiming the USAF had illegally handled toxic materials, and that the EPA had failed in its duty to enforce the Resource Conservation and Recovery Act (which governs handling of dangerous materials).',\n",
       "  'They also sought detailed information about the chemicals to which they were allegedly exposed, hoping this would facilitate the medical treatment of survivors.',\n",
       "  'Congressman Lee H. Hamilton, former chairman of the House Intelligence Committee, told 60 Minutes reporter Lesley Stahl, \"The Air Force is classifying all information about Area 51 in order to protect themselves from a lawsuit.\"'],\n",
       " 'answer': 'Rutgers University biochemists',\n",
       " 'answer_start': 457,\n",
       " 'gt_sentence': 'Biopsies taken from the complainants were analyzed by Rutgers University biochemists, who found high levels of dioxin, dibenzofuran, and trichloroethylene in their body fat.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlqa_xx_dataset['en']['test'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute question-sentence similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Load mUSE_small (v3) model (as a baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:25:42.613822Z",
     "iopub.status.busy": "2022-06-14T09:25:42.613593Z",
     "iopub.status.idle": "2022-06-14T09:32:56.562260Z",
     "shell.execute_reply": "2022-06-14T09:32:56.561136Z",
     "shell.execute_reply.started": "2022-06-14T09:25:42.613798Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "muse_small_v3_model = load_model('https://tfhub.dev/google/universal-sentence-encoder-multilingual/3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Load teacher models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-14T09:32:56.562723Z",
     "iopub.status.idle": "2022-06-14T09:32:56.562967Z",
     "shell.execute_reply": "2022-06-14T09:32:56.562842Z",
     "shell.execute_reply.started": "2022-06-14T09:32:56.562829Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "XQUAD_TEACHER_DIR = '../../../../CL-ReLKT_store/models/XQUAD/teacher_model/'\n",
    "MLQA_TEACHER_DIR = '../../../../CL-ReLKT_store/models/MLQA/teacher_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xquad_teacher_model = load_model(XQUAD_TEACHER_DIR)\n",
    "mlqa_teacher_model = load_model(MLQA_TEACHER_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Load student models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XQUAD_STUDENT_SUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XQUAD/student_best_supported_languages/'\n",
    "XQUAD_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XQUAD/student_best_unsupported_languages/'\n",
    "\n",
    "XORQA_STUDENT_SUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XORQA/student_best_supported_languages/'\n",
    "XORQA_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XORQA/student_best_unsupported_languages/'\n",
    "\n",
    "MLQA_STUDENT_SUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/MLQA/student_best_supported_languages/'\n",
    "MLQA_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/MLQA/student_best_unsupported_languages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xquad_student_supported_langs_model = load_model(XQUAD_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "xorqa_student_supported_langs_model = load_model(XORQA_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "mlqa_student_supported_langs_model = load_model(MLQA_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "\n",
    "xquad_student_unsupported_langs_model = load_model(XQUAD_STUDENT_UNSUPPORTED_LANGS_DIR)\n",
    "xorqa_student_unsupported_langs_model = load_model(XORQA_STUDENT_UNSUPPORTED_LANGS_DIR)\n",
    "mlqa_student_unsupported_langs_model = load_model(MLQA_STUDENT_UNSUPPORTED_LANGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MAPPING = {\n",
    "  # mUSE_small\n",
    "  'model-muse_small_v3': muse_small_v3_model,\n",
    "  # teacher    \n",
    "  'model-xquad_teacher': xquad_teacher_model,\n",
    "  'model-mlqa_teacher': mlqa_teacher_model,\n",
    "  # student\n",
    "  'model-xquad_student_supported_langs': xquad_student_supported_langs_model,\n",
    "  'model-xorqa_student_supported_langs': xorqa_student_supported_langs_model,\n",
    "  'model-mlqa_student_supported_langs': mlqa_student_supported_langs_model,\n",
    "  'model-xquad_student_unsupported_langs': xquad_student_unsupported_langs_model,\n",
    "  'model-xorqa_student_unsupported_langs': xorqa_student_unsupported_langs_model,\n",
    "  'model-mlqa_student_unsupported_langs': mlqa_student_unsupported_langs_model,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:22:30.713341Z",
     "iopub.status.busy": "2022-06-14T10:22:30.713175Z",
     "iopub.status.idle": "2022-06-14T10:22:30.720107Z",
     "shell.execute_reply": "2022-06-14T10:22:30.718877Z",
     "shell.execute_reply.started": "2022-06-14T10:22:30.713320Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_MAPPING = {}\n",
    "for lang in list(MLQA_LANGS):\n",
    "    DATASET_MAPPING[f'dataset-mlqa_{lang.strip()}_val'] = mlqa_xx_dataset[lang]['val']\n",
    "    DATASET_MAPPING[f'dataset-mlqa_{lang.strip()}_test'] = mlqa_xx_dataset[lang]['test']\n",
    "    \n",
    "print(DATASET_MAPPING.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Run inference and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function `run_online_prompt_mining` iterates over question-answer-passage triplets $(q_i, a_i, p_i)$ and compute \n",
    "the cosine similarity scores between question $q_i$ and segmented setences $s^i_j \\textrm{ where } p_i = ( s^i_0, \\ldots , s^i_{|p_i| - 1} )$ , and rank each quesiton-sentence pair by similairy score. Then, it evaluate the sentence-level precision@k.  Note: There is only 1 groundtruth sentence (i.e. the sentence where the answer span is a part of). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_en_val\n",
      "\n",
      " - model_prefix: model-muse_small_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1148/1148 [02:24<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7125\n",
      "\t - precision_at_k:\n",
      "{1: 0.7125435540069687,\n",
      " 2: 0.8614982578397212,\n",
      " 3: 0.9242160278745645,\n",
      " 4: 0.9512195121951219,\n",
      " 5: 0.9634146341463414,\n",
      " 6: 0.9747386759581882,\n",
      " 7: 0.9825783972125436,\n",
      " 8: 0.9878048780487805,\n",
      " 9: 0.9895470383275261,\n",
      " 10: 0.9912891986062717}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1148/1148 [02:05<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7247\n",
      "\t - precision_at_k:\n",
      "{1: 0.7247386759581882,\n",
      " 2: 0.8641114982578397,\n",
      " 3: 0.9259581881533101,\n",
      " 4: 0.9494773519163763,\n",
      " 5: 0.9651567944250871,\n",
      " 6: 0.975609756097561,\n",
      " 7: 0.985191637630662,\n",
      " 8: 0.9878048780487805,\n",
      " 9: 0.9895470383275261,\n",
      " 10: 0.9921602787456446}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1148/1148 [02:21<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7265\n",
      "\t - precision_at_k:\n",
      "{1: 0.7264808362369338,\n",
      " 2: 0.8693379790940766,\n",
      " 3: 0.9233449477351916,\n",
      " 4: 0.9494773519163763,\n",
      " 5: 0.9651567944250871,\n",
      " 6: 0.9747386759581882,\n",
      " 7: 0.9817073170731707,\n",
      " 8: 0.990418118466899,\n",
      " 9: 0.9912891986062717,\n",
      " 10: 0.9930313588850174}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xquad_student_supported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1148/1148 [02:22<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5166\n",
      "\t - precision_at_k:\n",
      "{1: 0.5165505226480837,\n",
      " 2: 0.7125435540069687,\n",
      " 3: 0.823170731707317,\n",
      " 4: 0.8797909407665505,\n",
      " 5: 0.9172473867595818,\n",
      " 6: 0.9416376306620209,\n",
      " 7: 0.9581881533101045,\n",
      " 8: 0.9686411149825784,\n",
      " 9: 0.9747386759581882,\n",
      " 10: 0.980836236933798}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xorqa_student_supported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1148/1148 [02:19<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6916\n",
      "\t - precision_at_k:\n",
      "{1: 0.6916376306620209,\n",
      " 2: 0.8336236933797909,\n",
      " 3: 0.9033101045296167,\n",
      " 4: 0.9346689895470384,\n",
      " 5: 0.9512195121951219,\n",
      " 6: 0.9686411149825784,\n",
      " 7: 0.9799651567944251,\n",
      " 8: 0.9843205574912892,\n",
      " 9: 0.9895470383275261,\n",
      " 10: 0.9921602787456446}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_student_supported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1148/1148 [02:22<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7265\n",
      "\t - precision_at_k:\n",
      "{1: 0.7264808362369338,\n",
      " 2: 0.8667247386759582,\n",
      " 3: 0.921602787456446,\n",
      " 4: 0.9477351916376306,\n",
      " 5: 0.9634146341463414,\n",
      " 6: 0.9738675958188153,\n",
      " 7: 0.9825783972125436,\n",
      " 8: 0.990418118466899,\n",
      " 9: 0.990418118466899,\n",
      " 10: 0.9930313588850174}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xquad_student_unsupported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1148/1148 [02:26<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.4007\n",
      "\t - precision_at_k:\n",
      "{1: 0.40069686411149824,\n",
      " 2: 0.5984320557491289,\n",
      " 3: 0.7412891986062717,\n",
      " 4: 0.8310104529616724,\n",
      " 5: 0.8806620209059234,\n",
      " 6: 0.9111498257839721,\n",
      " 7: 0.936411149825784,\n",
      " 8: 0.9503484320557491,\n",
      " 9: 0.9625435540069687,\n",
      " 10: 0.9686411149825784}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xorqa_student_unsupported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1148/1148 [02:23<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6838\n",
      "\t - precision_at_k:\n",
      "{1: 0.6837979094076655,\n",
      " 2: 0.8153310104529616,\n",
      " 3: 0.89198606271777,\n",
      " 4: 0.936411149825784,\n",
      " 5: 0.9529616724738676,\n",
      " 6: 0.9660278745644599,\n",
      " 7: 0.980836236933798,\n",
      " 8: 0.9843205574912892,\n",
      " 9: 0.9886759581881533,\n",
      " 10: 0.990418118466899}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_student_unsupported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1148/1148 [02:23<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7073\n",
      "\t - precision_at_k:\n",
      "{1: 0.7073170731707317,\n",
      " 2: 0.8466898954703833,\n",
      " 3: 0.912020905923345,\n",
      " 4: 0.9442508710801394,\n",
      " 5: 0.9590592334494773,\n",
      " 6: 0.9703832752613241,\n",
      " 7: 0.980836236933798,\n",
      " 8: 0.9869337979094077,\n",
      " 9: 0.9886759581881533,\n",
      " 10: 0.9921602787456446}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_en_test\n",
      "\n",
      " - model_prefix: model-muse_small_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11590/11590 [23:08<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6963\n",
      "\t - precision_at_k:\n",
      "{1: 0.6962899050905953,\n",
      " 2: 0.844521138912856,\n",
      " 3: 0.911130284728214,\n",
      " 4: 0.9438308886971527,\n",
      " 5: 0.9614322691975842,\n",
      " 6: 0.9720448662640208,\n",
      " 7: 0.9811044003451251,\n",
      " 8: 0.9855910267471959,\n",
      " 9: 0.9883520276100086,\n",
      " 10: 0.9907679033649698}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11590/11590 [23:19<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7035\n",
      "\t - precision_at_k:\n",
      "{1: 0.7034512510785159,\n",
      " 2: 0.8440897325280414,\n",
      " 3: 0.9097497842968076,\n",
      " 4: 0.9440034512510785,\n",
      " 5: 0.962381363244176,\n",
      " 6: 0.9715271786022434,\n",
      " 7: 0.9805004314063848,\n",
      " 8: 0.9858498705780846,\n",
      " 9: 0.9885245901639345,\n",
      " 10: 0.991458153580673}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11590/11590 [23:30<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7112\n",
      "\t - precision_at_k:\n",
      "{1: 0.7112165660051769,\n",
      " 2: 0.8484037963761863,\n",
      " 3: 0.9101811906816221,\n",
      " 4: 0.9446937014667817,\n",
      " 5: 0.9602243313201035,\n",
      " 6: 0.9715271786022434,\n",
      " 7: 0.980327868852459,\n",
      " 8: 0.9855910267471959,\n",
      " 9: 0.9891285591026747,\n",
      " 10: 0.9904227782571182}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xquad_student_supported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 710/11590 [01:26<23:32,  7.70it/s]"
     ]
    }
   ],
   "source": [
    "results = defaultdict(lambda : defaultdict())\n",
    "\n",
    "for dataset_prefix, dataset in DATASET_MAPPING.items():\n",
    "    print(f'\\n\\ndataset_prefix: {dataset_prefix}')\n",
    "    for model_prefix, model in MODEL_MAPPING.items():\n",
    "        \n",
    "        print(f'\\n - model_prefix: {model_prefix}')\n",
    "        prefix = f'{dataset_prefix}+{model_prefix}'\n",
    "        _result = run_online_prompt_mining(dataset,\n",
    "                             prefix=f'{dataset_prefix}_{model_prefix}',\n",
    "                             model=model)\n",
    "\n",
    "\n",
    "        results[dataset_prefix][model_prefix] = _result\n",
    "        print('--'*50)\n",
    "    print('\\n')    \n",
    "    print('=='*50)\n",
    "    print('\\n')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Write result as JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results, open('./eval_results.dataset_name-mlqa.json', 'w'), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convert evaluation results to a pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.load(open('./eval_results.dataset_name-mlqa.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(results.keys()), len(list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_objs = []\n",
    "for dataset_name, result_model_group in results.items():\n",
    "    for model_name, (metric, raw_result) in result_model_group.items():\n",
    "        top1, precision_at_k = metric\n",
    "        \n",
    "        result_objs.append({\n",
    "            'dataset_name': dataset_name,\n",
    "            'model_name': model_name,\n",
    "            'precision_at_1': top1,\n",
    "            'precision_at_2': precision_at_k['2'],\n",
    "            'precision_at_3': precision_at_k['6'],\n",
    "            'precision_at_4': precision_at_k['4'],\n",
    "            'precision_at_5': precision_at_k['5'],\n",
    "            'precision_at_10': precision_at_k['10'],\n",
    "        })\n",
    "    \n",
    "df = pd.DataFrame.from_dict(result_objs)\n",
    "df.to_csv('./eval_results.dataset_name-mlqa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
